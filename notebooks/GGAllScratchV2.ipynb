{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GGAllScratchV2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "15Ia_IXOb182",
        "nbrHg7Dbb19W"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "d8B4EjHfvJex",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gZPkTOPfwaAD",
        "colab_type": "code",
        "outputId": "53187609-b95b-414b-cb8b-2bc8ec111d9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "cd gdrive/My\\ Drive/NNFL\\ Project/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/NNFL Project\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VKuBkOOkwp8w",
        "colab_type": "code",
        "outputId": "5836a66e-c13a-4dc8-a49b-d438e1184171",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        }
      },
      "cell_type": "code",
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'AllScratch -  BEST.ipynb'   im1.png             imagenp.npy\n",
            " AllScratch.ipynb            im2.png             label_encoder.pickle\n",
            " AllScratchV2.ipynb          im3.png             \u001b[0m\u001b[01;34mTraining\u001b[0m/\n",
            " \u001b[01;34mcheckpointsV2\u001b[0m/              im4.png             Training.zip\n",
            " embedding_matrix.pickle     im5.png             word_index.pickle\n",
            " GGAllScratchV2.ipynb        im6.png\n",
            " glove.6B.200d.txt           image_dict.pickle\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kV6HynbFb110",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### CREATING IMAGE PRE-MODEL (4096 OUTPUT) ###"
      ]
    },
    {
      "metadata": {
        "id": "OaNaXWvub11_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from keras.applications.vgg16 import VGG16\n",
        "\n",
        "# base_model = VGG16()\n",
        "# # print(base_model.summary())\n",
        "\n",
        "# # get output of penultimate layer\n",
        "# from keras.models import Model\n",
        "# model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vqkMcRTzb12d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from keras.preprocessing.image import load_img\n",
        "# from keras.preprocessing.image import img_to_array\n",
        "# from keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "# # load an image from file\n",
        "# image = load_img('Coffee-Mug.jpg', target_size=(224, 224))\n",
        "# # convert the image pixels to a numpy array\n",
        "# image = img_to_array(image)\n",
        "# # reshape data for the model\n",
        "# image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "# # prepare the image for the VGG model\n",
        "# image = preprocess_input(image)\n",
        "\n",
        "# # predict the probability across all output classes\n",
        "# yhat = model.predict(image)\n",
        "# print(yhat.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s5aQjcxPb12t",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### MAKE IMAGE DATA DICT ###\n",
        "##### key: image name\n",
        "##### value: vector of shape [1,4096], output of VGGNet"
      ]
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "dy7-819Wb12z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# imagedictv2: Images of size 100x100\n",
        "\n",
        "if(os.path.isfile('image_dict.pickle')):\n",
        "    with open('image_dict.pickle', 'rb') as handle:\n",
        "        image_dict = pickle.load(handle)\n",
        "        \n",
        "# else:\n",
        "#   folder = 'Training/images/'\n",
        "\n",
        "#   image_dict_V2 = {}        \n",
        "\n",
        "#   skipped = []\n",
        "#   i=0\n",
        "\n",
        "#   for filename in os.listdir(folder):\n",
        "#       if(i%50 == 0):\n",
        "#           print(\"{} images processed\".format(i))\n",
        "#       i+=1\n",
        "#       if filename in image_dict_V2:\n",
        "#           # print (\"already in dict - moving on\")\n",
        "#           continue\n",
        "#       try:\n",
        "#           # load an image from file\n",
        "#           image = cv2.imread(os.path.join(folder, filename))\n",
        "#       except:\n",
        "#           print(\"Error reading file: {}!!!\".format(filename))\n",
        "#           skipped.append(filename)\n",
        "#           continue\n",
        "#       if image is not None:\n",
        "#           resized_image = cv2.resize(image, (100, 100)) \n",
        "#           image_dict_V2[filename] = resized_image\n",
        "#       else:\n",
        "#           skipped.append(filename)\n",
        "\n",
        "#   print(\"{} files skipped:\".format(len(skipped)))\n",
        "#   for f in skipped:\n",
        "#       print(\"    {}\".format(f))\n",
        "#   print(\"dict created\")\n",
        "\n",
        "\n",
        "#   print(\"Saving image_dict_V2.pickle\")\n",
        "#   with open('image_dict_V2.pickle', 'wb') as handle:\n",
        "#       pickle.dump(image_dict_V2, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "#       print('image_dict_V2.pickle saved')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "I1MtLpmTb13k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### CREATE QUESTION DATA ###"
      ]
    },
    {
      "metadata": {
        "id": "CNoizfX8b13t",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# create 2 lists\n",
        "# one stores image ids\n",
        "# one stores question\n",
        "\n",
        "imageNamesX  = []\n",
        "questionsNLX = []\n",
        "answers = []\n",
        "\n",
        "import json\n",
        "QAs = json.load(open(\"Training/Quest_Answers.json\", 'r'))['quest_answers']\n",
        "\n",
        "for QA in QAs:\n",
        "    img_name = QA[\"Image\"]+\".png\"\n",
        "    ques = QA[\"Question\"]\n",
        "    ans = QA[\"Answer\"]\n",
        "    \n",
        "    if img_name not in image_dict:\n",
        "        print(\"Skipping {} - not found in dict\".format(img))\n",
        "        continue\n",
        "    \n",
        "    imageNamesX.append(img_name)\n",
        "    questionsNLX.append(ques)\n",
        "    answers.append(ans)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SrFwWlUYb139",
        "colab_type": "code",
        "outputId": "a3bb2b57-3a3b-42a7-ba07-1f05a2771307",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "cell_type": "code",
      "source": [
        "### NOW do word embeddings for questions\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "num_words = 80\n",
        "tokenizer = Tokenizer(num_words=num_words, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True,split=' ')\n",
        "tokenizer.fit_on_texts(questionsNLX)\n",
        "questionsX = tokenizer.texts_to_sequences(questionsNLX)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "print('Found %s unique tokens.' % len(word_index))\n",
        "\n",
        "max_length_of_text = 200\n",
        "questionsX = pad_sequences(questionsX, maxlen=max_length_of_text)\n",
        "\n",
        "print(\"Saving word_index.pickle\")\n",
        "import pickle\n",
        "with open('word_index.pickle', 'wb') as handle:\n",
        "    pickle.dump(word_index, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "print(\"Saved.\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 80 unique tokens.\n",
            "Saving word_index.pickle\n",
            "Saved.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F4chPV40b14X",
        "colab_type": "code",
        "outputId": "a93dfd4a-332f-4961-a380-31e395ed0cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "# vector embeddings\n",
        "\n",
        "embeddings_index = {}\n",
        "    \n",
        "EMBEDDING_DIM = 200\n",
        "\n",
        "embedding_matrix = None\n",
        "if(os.path.isfile('embedding_matrix.pickle')):\n",
        "    print(\">> Embedding Matrix Pickle found...\")\n",
        "    with open('embedding_matrix.pickle', 'rb') as handle:\n",
        "        embedding_matrix = pickle.load(handle)\n",
        "    print(\">>> loaded!\")\n",
        "else:\n",
        "    f = open('glove.6B.200d.txt', encoding=\"utf8\")\n",
        "\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        embeddings_index[word] = coefs\n",
        "    f.close()\n",
        "\n",
        "    print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "    embedding_matrix = np.zeros((len(word_index)+1, EMBEDDING_DIM))\n",
        "    for word, i in word_index.items():\n",
        "        embedding_vector = embeddings_index.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            # words not found in embedding index will be all-zeros.\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "            \n",
        "    with open('embedding_matrix.pickle', 'wb') as handle:\n",
        "        pickle.dump(embedding_matrix, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "        print('embedding_matrix.pickle saved')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">> Embedding Matrix Pickle found...\n",
            ">>> loaded!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KjyTsLrd_8mZ",
        "colab_type": "code",
        "outputId": "baab387b-c162-45df-bc19-63b8311076b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "embedding_matrix.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(81, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "metadata": {
        "id": "aDWuAicZb15C",
        "colab_type": "code",
        "outputId": "c8acc08f-07a9-4d84-b23b-ada056a72db9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "# One hot encode answers\n",
        "\n",
        "## ONE HOT\n",
        "from numpy import array\n",
        "from numpy import argmax\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "data = answers\n",
        "values = array(data)\n",
        "# print(values)\n",
        "# integer encode\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(values)\n",
        "# print(integer_encoded)\n",
        "# binary encode\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "\n",
        "Y = onehot_encoded\n",
        "\n",
        "print(\"Saving label_encoder.pickle\")\n",
        "import pickle\n",
        "with open('label_encoder.pickle', 'wb') as handle:\n",
        "    pickle.dump(label_encoder, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "    print('label_encoder.pickle saved')\n",
        "\n",
        "# print(onehot_encoded)\n",
        "# invert first example\n",
        "# inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
        "# print(inverted)\n",
        "\n",
        "def decode_predictions(label_encoder, predictions):\n",
        "    texts = []\n",
        "    for p in predictions:\n",
        "        text = label_encoder.inverse_transform(argmax(p))\n",
        "        texts.append(text)\n",
        "    return texts\n",
        "\n",
        "label_encoder.classes_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving label_encoder.pickle\n",
            "label_encoder.pickle saved\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '1', '2', '3', '4', '5', '6', '7', '8', 'False', 'True',\n",
              "       'blue', 'brown', 'cube', 'cyan', 'cylinder', 'gray', 'green',\n",
              "       'large', 'metal', 'purple', 'red', 'rubber', 'small', 'sphere',\n",
              "       'yellow'], dtype='<U21')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 58
        }
      ]
    },
    {
      "metadata": {
        "id": "5hTacgoWb15f",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Split quesionsX\n",
        "from sklearn.model_selection import train_test_split\n",
        "imageNamesX_train, imageNamesX_test, questionsX_train, questionsX_test, Y_train, Y_test = train_test_split(imageNamesX, questionsX, Y, test_size=0.1, random_state=42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Rh4cxyvub15r",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data generator ###"
      ]
    },
    {
      "metadata": {
        "id": "6UZCIZfQb15w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def generator(image_dict, img_names, questions, labels, batch_size):\n",
        "#     # Create empty arrays to contain batch of features and labels\n",
        "    \n",
        "# #     batch_features = np.zeros((batch_size, 64, 64, 3))\n",
        "# #     batch_labels = np.zeros((batch_size,1))\n",
        "    \n",
        "#     q_ptr = 0\n",
        "#     batch_features = []\n",
        "#     batch_labels = []\n",
        "#     while True:\n",
        "#         for i in range(batch_size):\n",
        "#             if q_ptr == len(questions):\n",
        "#                 q_ptr = 0\n",
        "#             index = q_ptr\n",
        "#             # print(imageNamesX[q_ptr].shape)\n",
        "#             # print(questionsX[q_ptr])\n",
        "#             batch_features.append(np.concatenate((image_dict[img_names[index]], questions[index]), axis = None))\n",
        "#             batch_labels.append(Y[index])\n",
        "#             q_ptr+=1\n",
        "#         yield np.array(batch_features), np.array(batch_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bEkzqWKYb16C",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# A, B = generator(image_dict, imageNamesX, questionsX, Y, 10)\n",
        "# print(A)\n",
        "# print(B)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MXKbN6Nrb16T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generator(image_dict, img_names, questions, labels, batch_size):\n",
        "    \n",
        "    q_ptr = 0\n",
        "    while True:\n",
        "        image_inp = []\n",
        "        q_inp = []\n",
        "        batch_labels = []\n",
        "        for i in range(batch_size):\n",
        "            if q_ptr == len(questions):\n",
        "                q_ptr = 0\n",
        "            index = q_ptr\n",
        "#             import random\n",
        "#             index= random.randint(0, len(questions)-1)\n",
        "            # print(imageNamesX[q_ptr].shape)\n",
        "            # print(questionsX[q_ptr])\n",
        "            image_inp.append(image_dict[img_names[index]])\n",
        "            q_inp.append(questions[index])\n",
        "            batch_labels.append(labels[index])\n",
        "            q_ptr+=1\n",
        "            \n",
        "        yield [np.array(image_inp), np.array(q_inp)], np.array(batch_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lk8vTG9Jb16k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# def test_generator(image_dict, img_names, questions, labels, batch_size):\n",
        "    \n",
        "#     q_ptr = 0\n",
        "#     while True:\n",
        "#         image_inp = []\n",
        "#         q_inp = []\n",
        "#         batch_labels = []\n",
        "#         for i in range(batch_size):\n",
        "#             if q_ptr == len(questions):\n",
        "#                 q_ptr = 0\n",
        "#             index = q_ptr\n",
        "# #             import random\n",
        "# #             index= random.randint(0, len(questions)-1)\n",
        "#             # print(imageNamesX[q_ptr].shape)\n",
        "#             # print(questionsX[q_ptr])\n",
        "#             image_inp.append(image_dict[img_names[index]])\n",
        "#             q_inp.append(questions[index])\n",
        "#             batch_labels.append(labels[index])\n",
        "#             q_ptr+=1\n",
        "#         yield [np.array(image_inp), np.array(q_inp)], np.array(batch_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "v8YOoAnsb16w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "# from keras.layers import Input, LSTM, Embedding, Dense\n",
        "# from keras.models import Model, Sequential\n",
        "# import keras\n",
        "\n",
        "# # Define CNN for Image Input\n",
        "# vision_model = Sequential()\n",
        "# vision_model.add(Conv2D(64, (3, 3), activation='relu', padding='same', input_shape=(224, 224, 3)))\n",
        "# vision_model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "# vision_model.add(MaxPooling2D((2, 2)))\n",
        "# vision_model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
        "# vision_model.add(Conv2D(128, (3, 3), activation='relu'))\n",
        "# vision_model.add(MaxPooling2D((2, 2)))\n",
        "# vision_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
        "# vision_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "# vision_model.add(Conv2D(256, (3, 3), activation='relu'))\n",
        "# vision_model.add(MaxPooling2D((2, 2)))\n",
        "# vision_model.add(Flatten())\n",
        "\n",
        "# image_input = Input(shape=(224, 224, 3))\n",
        "# encoded_image = vision_model(image_input)\n",
        "\n",
        "# # Define RNN for language input\n",
        "# question_input = Input(shape=(100,), dtype='int32')\n",
        "# embedded_question = Embedding(input_dim=10000, output_dim=256, input_length=100)(question_input)\n",
        "# encoded_question = LSTM(256)(embedded_question)\n",
        "\n",
        "# # Combine CNN and RNN to create the final model\n",
        "# merged = keras.layers.concatenate([encoded_question, encoded_image])\n",
        "# output = Dense(1000, activation='softmax')(merged)\n",
        "# vqa_model = Model(inputs=[image_input, question_input], outputs=output)\n",
        "\n",
        "# print(vqa_model.summary())\n",
        "\n",
        "# vqa_model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
        "#         metrics=['accuracy'])\n",
        "\n",
        "# vqa_model.fit_generator(generator2(image_dict, imageNamesX, questionsX, Y, 10), samples_per_epoch=50, nb_epoch=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kouDJjIJb167",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### MODELS ###"
      ]
    },
    {
      "metadata": {
        "id": "1BEBLNAxb17O",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#BEST\n",
        "def vqa_model0(embedding_matrix, num_words, embedding_dim, seq_length, dropout_rate, num_classes):\n",
        "    import vqa_model0\n",
        "    model = vqa_model0.get_model(embedding_matrix, num_words, embedding_dim, seq_length, dropout_rate, num_classes)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nhtss9nab17x",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def vqa_model1(embedding_matrix, num_words, embedding_dim, seq_length, dropout_rate, num_classes):\n",
        "    import vqa_model1\n",
        "    model = vqa_model1.get_model(embedding_matrix, num_words, embedding_dim, seq_length, dropout_rate, num_classes)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9HFwsw2Vb18A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#ANet Experiment\n",
        "def vqa_model3(embedding_matrix, num_words, embedding_dim, seq_length, dropout_rate, num_classes):\n",
        "    import vqa_model3\n",
        "    model = vqa_model3.get_model(embedding_matrix, num_words, embedding_dim, seq_length, dropout_rate, num_classes)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lc8CR5QO_IBE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential, Model\n",
        "from keras.layers import Input, Dense, Activation, Dropout, LSTM, Flatten, Embedding, Multiply, Concatenate\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
        "import keras\n",
        "\n",
        "def vqa_model(embedding_matrix, num_words, embedding_dim, seq_length, dropout_rate, num_classes):\n",
        "    \n",
        "    print(\"Creating image model...\")\n",
        "    img_model = Sequential()\n",
        "    img_model.add(Dense(1024, input_dim=4096, activation='tanh'))\n",
        "\n",
        "    image_input = Input(shape=(4096, ))\n",
        "    encoded_image = img_model(image_input)\n",
        "\n",
        "    print(\"Creating text model...\")\n",
        "    txt_model = Sequential()\n",
        "    txt_model.add(Embedding(num_words, embedding_dim, \n",
        "        weights=[embedding_matrix], input_length=seq_length, trainable=False))\n",
        "    txt_model.add(LSTM(units=512, return_sequences=True, input_shape=(seq_length, embedding_dim)))\n",
        "    txt_model.add(Dropout(dropout_rate))\n",
        "    txt_model.add(LSTM(units=512, return_sequences=False))\n",
        "    txt_model.add(Dropout(dropout_rate))\n",
        "    txt_model.add(Dense(1024, activation='tanh'))\n",
        "    \n",
        "    question_input = Input(shape=(EMBEDDING_DIM, ), dtype='int32')\n",
        "    embedded_question = txt_model(question_input)\n",
        "    \n",
        "    print(\"Merging final model...\")\n",
        "    merged = keras.layers.concatenate([encoded_image, embedded_question])\n",
        "    d1  = Dense(1000, activation='softmax')(merged)\n",
        "    dp1 = Dropout(dropout_rate)(d1)\n",
        "    d2  = Dense(1000, activation='tanh')(dp1)\n",
        "    dp2 = Dropout(dropout_rate)(d2)\n",
        "    output  = Dense(num_classes, activation='softmax')(dp2)\n",
        "    \n",
        "    vqa_model = Model(inputs=[image_input, question_input], outputs=output)\n",
        "    \n",
        "    \n",
        "#     fc_model = Sequential()\n",
        "#     # fc_model.add(Merge([vgg_model, lstm_model], mode='mul'))\n",
        "#     fc_model.add(Concatenate([img_model, txt_model]))\n",
        "#     fc_model.add(Dropout(dropout_rate))\n",
        "#     fc_model.add(Dense(1000, activation='tanh'))\n",
        "#     fc_model.add(Dropout(dropout_rate))\n",
        "#     fc_model.add(Dense(num_classes, activation='softmax'))\n",
        "    \n",
        "    vqa_model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    \n",
        "    return vqa_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XSwkRzIeb18V",
        "colab_type": "code",
        "outputId": "60e07f53-abe1-4297-987a-556b48a0a43e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1244
        }
      },
      "cell_type": "code",
      "source": [
        "dropout_rate=0.5\n",
        "num_classes=26\n",
        "model_weights_filename = \"weightsV2.bkp\"\n",
        "ckpt_model_weights_filename = \"checkpointsV2/checkP.cp\"\n",
        "\n",
        "model = None\n",
        "if os.path.exists(ckpt_model_weights_filename):\n",
        "    print(\"Loading model: {}\".format(ckpt_model_weights_filename))\n",
        "    from keras.models import load_model\n",
        "    model = load_model(ckpt_model_weights_filename)\n",
        "else:\n",
        "    model = vqa_model(embedding_matrix, num_words, EMBEDDING_DIM, max_length_of_text, dropout_rate, num_classes)\n",
        "    if os.path.exists(model_weights_filename):\n",
        "        print (\"Loading Weights...\")\n",
        "        model.load_weights(model_weights_filename)\n",
        "    \n",
        "# print(model.summary())\n",
        "\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "checkpointer = ModelCheckpoint(filepath=ckpt_model_weights_filename, verbose=1)\n",
        "\n",
        "batch_size = 10\n",
        "model.fit_generator(\n",
        "    generator(image_dict, imageNamesX_train, questionsX_train, Y_train, batch_size),\n",
        "    validation_data=generator(image_dict, imageNamesX_test, questionsX_test, Y_test, batch_size),\n",
        "    validation_steps=len(Y_test)/(batch_size-1), steps_per_epoch=len(Y_train)/(batch_size-1), nb_epoch=1, callbacks=[checkpointer])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Creating image model...\n",
            "Creating text model...\n",
            "Merging final model...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:26: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., validation_steps=1500.22222..., steps_per_epoch=13502.0, callbacks=[<keras.ca..., epochs=1)`\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1\n",
            "  728/13502 [>.............................] - ETA: 3:42:08 - loss: 2.6684 - acc: 0.2055"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-67-6a3af4d8f699>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimageNamesX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestionsX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimageNamesX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquestionsX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     validation_steps=len(Y_test)/(batch_size-1), steps_per_epoch=len(Y_train)/(batch_size-1), nb_epoch=1, callbacks=[checkpointer])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "15Ia_IXOb182",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### EXPERIMENTS ###"
      ]
    },
    {
      "metadata": {
        "id": "ontWB8WKb188",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# # EXPERIMENT\n",
        "# from sklearn.preprocessing import MultiLabelBinarizer\n",
        "# labels = [\"hello\", \"world\", \"hello\", \"cat\"]\n",
        "# mlb = MultiLabelBinarizer()\n",
        "# labels = mlb.fit_transform(labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SDEd5rXFb19N",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# ## ONE HOT\n",
        "# from numpy import array\n",
        "# from numpy import argmax\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "# # define example\n",
        "# data = ['cold', 'cold', 'warm', 'cold', 'hot', 'hot', 'warm', 'cold', 'warm', 'hot']\n",
        "# values = array(data)\n",
        "# print(values)\n",
        "# # integer encode\n",
        "# label_encoder = LabelEncoder()\n",
        "# integer_encoded = label_encoder.fit_transform(values)\n",
        "# print(integer_encoded)\n",
        "# # binary encode\n",
        "# onehot_encoder = OneHotEncoder(sparse=False)\n",
        "# integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "# onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
        "# print(onehot_encoded)\n",
        "# # # invert first example\n",
        "# # inverted = label_encoder.inverse_transform([argmax(onehot_encoded[0, :])])\n",
        "# # print(inverted)\n",
        "\n",
        "# def decode_prediction(predictions):\n",
        "#     texts = []\n",
        "#     for p in predictions:\n",
        "#         text = label_encoder.inverse_transform(argmax(p))\n",
        "#         texts.append(text)\n",
        "#     return texts\n",
        "    \n",
        "# asdf = []\n",
        "# asdf.append([1,0,0])\n",
        "# asdf.append([0,1,0])\n",
        "# asdf.append([0,0,1])\n",
        "    \n",
        "# print(decode_prediction(asdf))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": false,
        "id": "nbrHg7Dbb19W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### PLAY AROUND ###"
      ]
    },
    {
      "metadata": {
        "id": "dnf-DpxTb19Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cn4SROnZb19u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import argparse\n",
        "from keras.models import load_model\n",
        "import re\n",
        "import pickle\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# -------VARIABLES------- #\n",
        "max_length_of_text = 42\n",
        "# ----------------------- #\n",
        "\n",
        "def VGG_preprocess_images(images):\n",
        "    print(\"> VGG preprocessing images\")\n",
        "    \n",
        "    from keras.applications.vgg16 import VGG16\n",
        "    base_model = VGG16()\n",
        "    # print(base_model.summary())\n",
        "\n",
        "    # get output of penultimate layer\n",
        "    from keras.models import Model\n",
        "    model = Model(inputs=base_model.input, outputs=base_model.get_layer('fc2').output)\n",
        "\n",
        "    print(\">> VGG keras model loaded\")\n",
        "    \n",
        "    from keras.preprocessing.image import load_img\n",
        "    from keras.preprocessing.image import img_to_array\n",
        "    from keras.applications.vgg16 import preprocess_input\n",
        "    \n",
        "    resized_images = []\n",
        "    for image in images:\n",
        "        resized_image = cv2.resize(image, (224, 224)) \n",
        "        resized_images.append(resized_image)\n",
        "    \n",
        "    resized_images = np.array(resized_images)\n",
        "    print(resized_images.shape)\n",
        "        \n",
        "    # prepare the image for the VGG model\n",
        "    preprocessed_images = preprocess_input(resized_images)\n",
        "    \n",
        "    print(\">> Images VGG preprocessed!\")\n",
        "\n",
        "    # predict the probability across all output classes\n",
        "    results = model.predict(preprocessed_images)\n",
        "    \n",
        "    return results\n",
        "    \n",
        "def filter_string(str1, str2):\n",
        "    for c in str2:\n",
        "        str1 = str1.replace(c, '')\n",
        "    return str1\n",
        "\n",
        "def predict(model_path, images, questions, word_index):\n",
        "    print(\"> Loading our ML model...\")\n",
        "    model = load_model(model_path)\n",
        "    print(\">> model loaded\")\n",
        "    \n",
        "    # question is a list of NL questions\n",
        "    # convert to sequences\n",
        "    print(\"> Processing NL questions\")\n",
        "    X = []\n",
        "    for Q in questions:\n",
        "        temp = []\n",
        "        Q = filter_string(Q, '!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "        for word in Q.split():\n",
        "            if(word in word_index):\n",
        "                temp.append(word_index[word])\n",
        "        X.append(temp)    \n",
        "    X = pad_sequences(X, maxlen=max_length_of_text)\n",
        "    print(\">> Done!\")\n",
        "    \n",
        "#     print(\"\\nimages:\")\n",
        "#     print(images)\n",
        "    \n",
        "#     print(\"\\nX:\")\n",
        "#     print(X)\n",
        "    \n",
        "    print(\"> Predicting results\")\n",
        "    predictions = model.predict([np.array(images), np.array(X)])\n",
        "    return predictions\n",
        "\n",
        "def decode_predictions(label_encoder, predictions):\n",
        "    texts = []\n",
        "    for p in predictions:\n",
        "        top3 = []\n",
        "        s = np.argsort(p, axis=-1, kind='quicksort', order=None)\n",
        "        for i in range (len(s)-1, len(s)-6, -1):\n",
        "            text = label_encoder.inverse_transform(s[i])\n",
        "            top3.append(text)\n",
        "        texts.append(top3)\n",
        "    return texts\n",
        "\n",
        "def results_to_text(label_encoder, results):\n",
        "    print(\"> Converting model output to texts\")\n",
        "    texts = decode_predictions(label_encoder, results)\n",
        "    return texts\n",
        "\n",
        "def playground():\n",
        "    #make questions and images\n",
        "    questions = [\"How many spheres are present?\",\n",
        "                 \"What color is the large metallic ball\",\n",
        "                 \"How many cylinders are present\",\n",
        "                 \"What color is the large metallic ball that is in front of the metallic ball on the left side of the cylinder in front of the blue sphere?\",\n",
        "                 \"Are there more small metallic objects on the left side of the big purple metallic object than gray balls that are to the right of the tiny gray rubber ball?\",\n",
        "                 \"How many other objects are there of the same shape as the small blue matte thing?\"]\n",
        "    image_names = [\"im1.png\",\n",
        "                   \"im2.png\",\n",
        "                   \"im3.png\",\n",
        "                   \"im4.png\",\n",
        "                   \"im5.png\",\n",
        "                   \"im6.png\"]\n",
        "\n",
        "    images = []\n",
        "    for image_name in image_names:\n",
        "        image = cv2.imread(image_name)\n",
        "        resized_image = cv2.resize(image, (224, 224)) \n",
        "        images.append(resized_image)\n",
        "        \n",
        "    preprocessed_images = VGG_preprocess_images(images)\n",
        "\n",
        "    model_path = \"checkpoints/checkP.cp\"\n",
        "\n",
        "    word_index = None\n",
        "    with open('word_index.pickle', 'rb') as handle:\n",
        "        word_index = pickle.load(handle)\n",
        "    if word_index is not None:\n",
        "        print(\"\\n> word_index.pickle loaded.\")\n",
        "\n",
        "        results = predict(model_path, preprocessed_images, questions, word_index)\n",
        "        print(results)\n",
        "        \n",
        "        label_encoder = None\n",
        "        with open('label_encoder.pickle', 'rb') as handle:\n",
        "            label_encoder = pickle.load(handle)\n",
        "        texts = results_to_text(label_encoder, results)\n",
        "    \n",
        "        for i in range(0, len(questions)):\n",
        "            img = cv2.imread(image_names[i])\n",
        "            \n",
        "            from matplotlib import pyplot as plt\n",
        "            plt.imshow(img)\n",
        "            plt.show()\n",
        "            \n",
        "            Q = questions[i]\n",
        "            print(Q)\n",
        "            A = texts[i]\n",
        "            print(A)\n",
        "            print()\n",
        "\n",
        "    #     print(\"\\nSaving solution.csv...\")\n",
        "    #     new_df = pd.DataFrame({\"Index\": [i+1 for i in range (len(predictions))],\n",
        "    #                             \"Sentiment\": predictions})\n",
        "    #     new_df.to_csv(\"solution.csv\", index = False)\n",
        "    #     print(\"Saved.\")\n",
        "    else:\n",
        "        print(\"Sorry, word_index.pickle not found!\")\n",
        "        \n",
        "# print(\"Freeing GPU Memory...\")\n",
        "# # from numba import cuda\n",
        "# # cuda.select_device(0)\n",
        "# # cuda.close()\n",
        "\n",
        "# # from keras import backend as K\n",
        "# # K.clear_session()\n",
        "# print(\"Freed!\\n\")\n",
        "        \n",
        "playground()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sUpiZt7fb1-B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# from matplotlib import pyplot as plt\n",
        "# import cv2\n",
        "\n",
        "# img1 = cv2.imread(\"im1.png\")\n",
        "# img2 = cv2.imread(\"im2.png\")\n",
        "\n",
        "# plt.imshow(img1)\n",
        "# plt.show()\n",
        "# plt.imshow(img2)\n",
        "# plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YhDzc_P1b1-P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R6U6AMK6b1-W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}